{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FSL_Relationnet_custom_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Few Shot Learning with Relation net on custom data "
      ],
      "metadata": {
        "id": "lxUowry4aGyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing"
      ],
      "metadata": {
        "id": "oNXbTJn8aSf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount gdrive \n",
        "\n",
        "from google.colab import drive \n",
        "import os \n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe9iC1aEafcy",
        "outputId": "d11bc519-e204-4535-c34a-ce8316395c3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will clone this repo under this directory \n",
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/\")"
      ],
      "metadata": {
        "id": "SPReCOiXafhH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# git clone this repo \n",
        "!git clone https://github."
      ],
      "metadata": {
        "id": "7O8V8tEMamo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then change directory to build custom data set \n",
        "os.chdir(\"./FSL_Relationnet_custom_data/custom_data/\")"
      ],
      "metadata": {
        "id": "pkR1xXlDbfhO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## image tranformation"
      ],
      "metadata": {
        "id": "P6JwuVt9eBWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model requires certain square image input  \n",
        "\n",
        "# but too much error was corrupted during torch.transfrom \n",
        "# so I recommend that you should transfrom image using img.resize \n",
        "\n",
        "from glob import glob \n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "directr = \"/content/gdrive/MyDrive/Colab Notebooks/FSL_Relationnet_custom_data/custom_data/\"\n",
        "forfor = glob(directr+'*')\n",
        "print(forfor)\n",
        "\n",
        "for folds in forfor:\n",
        "  print(folds.split(\".\")[-1])\n",
        "\n",
        "for folds in forfor:\n",
        "    if folds.split(\".\")[-1] != \"json\" or \"py\":\n",
        "      print(\"collecting sub_folder root  files\")\n",
        "      \n",
        "      imgs = glob(folds + \"/*\")\n",
        "      print(imgs)\n",
        "\n",
        "      for f in imgs:\n",
        "        img = Image.open(f)\n",
        "        img_resize = img.resize((256, 256), Image.HAMMING)\n",
        "        img_resize.save(f)\n",
        "        img.close()\n",
        "      continue\n",
        "\n",
        "    if folds.split(\".\")[-1] == \"json\" or \"py\":\n",
        "      print(\"excluding json and py files\")\n",
        "      continue\n"
      ],
      "metadata": {
        "id": "GPJCT5meeEg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build custom data file"
      ],
      "metadata": {
        "id": "MEZqrXRfdoGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write_custom_data.py\n",
        "# > reads img file and writes json format files\n",
        "# > From line 50 ~ ( for-loops ) you should change labels and encodings \n",
        "\n",
        "!python write_custom_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8fx4IeNa6mt",
        "outputId": "04b92cdf-bb50-4833-ac00-1a7408fc238c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base -OK\n",
            "val -OK\n",
            "novel -OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tree structure of the custom dataset we need\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# prefix components:\n",
        "space =  '    '\n",
        "branch = '│   '\n",
        "# pointers:\n",
        "tee =    '├── '\n",
        "last =   '└── '\n",
        "\n",
        "\n",
        "def tree(dir_path: Path, prefix: str=''):\n",
        "    \"\"\"A recursive generator, given a directory Path object\n",
        "    will yield a visual tree structure line by line\n",
        "    with each line prefixed by the same characters\n",
        "    \"\"\"    \n",
        "    contents = list(dir_path.iterdir())\n",
        "    # contents each get pointers that are ├── with a final └── :\n",
        "    pointers = [tee] * (len(contents) - 1) + [last]\n",
        "    for pointer, path in zip(pointers, contents):\n",
        "        yield prefix + pointer + path.name\n",
        "        if path.is_dir(): # extend the prefix and recurse:\n",
        "            extension = branch if pointer == tee else space \n",
        "            # i.e. space because last, └── , above so no more |\n",
        "            yield from tree(path, prefix=prefix+extension)"
      ],
      "metadata": {
        "id": "swhfpakaaEmA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your dataset structure should be like this  \n",
        "# if your target folder is not same with current working directory,\n",
        "# change target_folder_dir \n",
        "\n",
        "target_folder_dir = os.getcwd()\n",
        "for line in tree(Path(target_folder_dir)):\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyi3Hb3TdB0C",
        "outputId": "1cd5e588-02f6-4c46-85d9-9dde36f28744"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "├── class1\n",
            "│   ├── img.02.png\n",
            "│   ├── img.01.png\n",
            "│   └── img.03.png\n",
            "├── class2\n",
            "│   ├── img.01.png\n",
            "│   ├── img.02.png\n",
            "│   └── img.03.png\n",
            "├── class3\n",
            "│   ├── img.02.png\n",
            "│   ├── img.03.png\n",
            "│   └── img.01.png\n",
            "├── base.json\n",
            "├── val.json\n",
            "├── novel.json\n",
            "└── write_custom_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run FSL\n"
      ],
      "metadata": {
        "id": "T6xFXDaadulv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/gdrive/MyDrive/Colab Notebooks/FSL_Relationnet_custom_data\")"
      ],
      "metadata": {
        "id": "gvjqIuwrdJn9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change configuration file "
      ],
      "metadata": {
        "id": "ImWJ77yHhoop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open configs.py and change the first and the last line \n",
        "\n",
        "# file is written this way \n",
        "\n",
        "#--> save_dir                 = '/content/gdrive/MyDrive/Colab Notebooks/FSL_Relationnet_custom_data'\n",
        "\n",
        "# data_dir = {}\n",
        "# data_dir['CUB']             = './filelists/CUB/' \n",
        "# data_dir['miniImagenet']    = './filelists/miniImagenet/' \n",
        "# data_dir['omniglot']        = './filelists/omniglot/' \n",
        "# data_dir['emnist']          = './filelists/emnist/' \n",
        "# data_dir['custom']        = '/content/gdrive/MyDrive/Colab Notebooks/FSL_Relationnet_custom_data/custom_data'\n",
        "\n",
        "#--> data_dir['custom'] = \"your custom data set directory \""
      ],
      "metadata": {
        "id": "CJMNmodehsIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you are prepared to run train.py file "
      ],
      "metadata": {
        "id": "9boP4JojiD28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if test_n_way is smaller than train_n_way, \n",
        "#reduce n_query to keep batch size small\n",
        "# test_n_way >= train_n_way\n",
        "# n-shot < number of data image\n",
        "\n",
        "# running time is measured \n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "print(\"---------------current start time ---------- : \" , start)\n",
        "!python train.py --dataset \"custom\" --method relationnet --test_n_way 2 --train_n_way 2 --n_shot 2 --num_classes 3 --start_epoch 0 --stop_epoch 5 --save_freq 2\n",
        "\n",
        "print(\"time :\", time.time() - start)"
      ],
      "metadata": {
        "id": "i7Bn9Nnfe5kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this step, you are changing trained model output ( tar file ) into hdf5 file \n",
        "\n",
        "# modify save_feature file > 74th Line\n",
        "# check output directory \n",
        "\n",
        "# if you change backbone and method \n",
        "# change 74th line \n",
        "\n",
        "# if you use different datset \n",
        "# change custom data directory in configs.py file \n",
        "\n",
        "\n",
        "!python save_features.py --dataset \"custom\" \\\n",
        "--method relationnet \\\n",
        "--model Conv4 \\\n",
        "--test_n_way 2 \\\n",
        "--train_n_way 2 \\\n",
        "--n_shot 2 \\\n",
        "--save_iter 4"
      ],
      "metadata": {
        "id": "GJNaHJrhe5m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run test with saved weight"
      ],
      "metadata": {
        "id": "fWdko3T9uqr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Only modify test.py file to change options  \n",
        "\n",
        "* line 25 : change n_query and n_support data set for eval\n",
        "\n",
        "* line 53 line -> iter num -> how many test we gonna apply \n",
        "\n",
        "* line 152 ~ 157 : \n",
        "change to load different hdf5 file ( root dirdirdir , Conv type, Network type, method, hwmany , file_type )\n",
        "\n",
        "* change config file when you change image directory ( using different image set ) "
      ],
      "metadata": {
        "id": "RC7CXgfRuz7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./test.py \\\n",
        "--dataset custom \\\n",
        "--method relationnet \\\n",
        "--train_n_way 2 \\\n",
        "--test_n_way 2 \\"
      ],
      "metadata": {
        "id": "O-fiNvWHe5pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checkout saved results"
      ],
      "metadata": {
        "id": "2qwv7jmOe6en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!xdg-open ./record/results.txt"
      ],
      "metadata": {
        "id": "aDMPowJTe5w3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}